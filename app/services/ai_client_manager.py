"""
AI å®¢æˆ·ç«¯ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å¤šä¸ª AI æä¾›å•†ï¼ˆOpenAIã€DeepSeekï¼‰

åŠŸèƒ½ï¼š
1. æ”¯æŒå¤šä¸ª AI æä¾›å•†ï¼ˆOpenAI ä¸»åŠ› + DeepSeek å…œåº•ï¼‰
2. è‡ªåŠ¨é™çº§ï¼šOpenAI å¤±è´¥æ—¶åˆ‡æ¢åˆ° DeepSeek
3. ç†”æ–­æœºåˆ¶ï¼šä¸´æ—¶å±è”½å¤±è´¥çš„æä¾›å•†
4. ç»Ÿä¸€çš„è°ƒç”¨æ¥å£

é™çº§ç­–ç•¥ï¼šOpenAI â†’ DeepSeek â†’ è§„åˆ™å¼•æ“
"""

import logging
from typing import Optional, Dict, Any, List, Tuple
from datetime import datetime, timedelta
from enum import Enum

from app.core.config import settings
from app.core.proxy import apply_proxy_env, ProxyConfig

logger = logging.getLogger(__name__)


class AIProvider(str, Enum):
    """AI æä¾›å•†æšä¸¾"""
    OPENAI = "openai"
    DEEPSEEK = "deepseek"


# å…¨å±€å®¢æˆ·ç«¯ç¼“å­˜
_clients: Dict[AIProvider, Any] = {}

# æä¾›å•†ç†”æ–­å™¨ï¼šè®°å½•ä¸´æ—¶ä¸å¯ç”¨çš„æä¾›å•†åŠå…¶æ¢å¤æ—¶é—´
_provider_circuit_breaker: Dict[AIProvider, float] = {}


def _init_openai_client():
    """åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯"""
    if not settings.OPENAI_API_KEY:
        logger.warning("OPENAI_API_KEY not configured")
        return None
    
    try:
        from openai import AsyncOpenAI
        
        # åº”ç”¨ä»£ç†é…ç½®
        apply_proxy_env(
            ProxyConfig(
                enabled=settings.PROXY_ENABLED,
                http_proxy=settings.HTTP_PROXY,
                https_proxy=settings.HTTPS_PROXY,
                no_proxy=settings.NO_PROXY,
            )
        )
        
        if settings.OPENAI_API_BASE:
            client = AsyncOpenAI(
                api_key=settings.OPENAI_API_KEY,
                base_url=settings.OPENAI_API_BASE,
                timeout=settings.OPENAI_TIMEOUT_SECONDS,
            )
        else:
            client = AsyncOpenAI(
                api_key=settings.OPENAI_API_KEY,
                timeout=settings.OPENAI_TIMEOUT_SECONDS,
            )
        
        logger.info("âœ… OpenAI client initialized")
        return client
    except ImportError:
        logger.error("openai package not installed, run: pip install openai")
        return None
    except Exception as e:
        logger.error(f"Failed to initialize OpenAI client: {e}")
        return None


def _init_deepseek_client():
    """åˆå§‹åŒ– DeepSeek å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨ OpenAI SDKï¼Œå…¼å®¹æ ¼å¼ï¼‰"""
    if not settings.DEEPSEEK_ENABLED:
        logger.info("DeepSeek disabled in config")
        return None
    
    if not settings.DEEPSEEK_API_KEY:
        logger.warning("DEEPSEEK_API_KEY not configured")
        return None
    
    try:
        from openai import AsyncOpenAI
        
        # DeepSeek API å®Œå…¨å…¼å®¹ OpenAI æ ¼å¼
        # reasoner æ¨¡å¼éœ€è¦æ›´é•¿çš„è¶…æ—¶æ—¶é—´
        timeout = getattr(settings, 'DEEPSEEK_TIMEOUT_SECONDS', 30)
        client = AsyncOpenAI(
            api_key=settings.DEEPSEEK_API_KEY,
            base_url=settings.DEEPSEEK_API_BASE,
            timeout=timeout,
        )
        
        logger.info("âœ… DeepSeek client initialized (base_url: %s, timeout: %ds)", settings.DEEPSEEK_API_BASE, timeout)
        return client
    except Exception as e:
        logger.error(f"Failed to initialize DeepSeek client: {e}")
        return None


def get_ai_client(provider: AIProvider = AIProvider.OPENAI):
    """
    è·å–æŒ‡å®š AI æä¾›å•†çš„å®¢æˆ·ç«¯ï¼ˆæ‡’åŠ è½½ + å…¨å±€å•ä¾‹ï¼‰
    
    Args:
        provider: AI æä¾›å•†
    
    Returns:
        AsyncOpenAI å®¢æˆ·ç«¯å®ä¾‹ï¼Œå¤±è´¥è¿”å› None
    """
    global _clients
    
    # æ£€æŸ¥ç†”æ–­å™¨
    if provider in _provider_circuit_breaker:
        recovery_time = _provider_circuit_breaker[provider]
        if datetime.now().timestamp() < recovery_time:
            remaining = int(recovery_time - datetime.now().timestamp())
            logger.warning(f"âš ï¸ {provider.value} is circuit-broken, recovery in {remaining}s")
            return None
        else:
            # ç†”æ–­æ¢å¤
            del _provider_circuit_breaker[provider]
            logger.info(f"âœ… {provider.value} circuit breaker recovered")
    
    # è¿”å›ç¼“å­˜çš„å®¢æˆ·ç«¯
    if provider in _clients and _clients[provider]:
        return _clients[provider]
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    if provider == AIProvider.OPENAI:
        _clients[provider] = _init_openai_client()
    elif provider == AIProvider.DEEPSEEK:
        _clients[provider] = _init_deepseek_client()
    else:
        logger.error(f"Unknown AI provider: {provider}")
        return None
    
    return _clients[provider]


def circuit_break_provider(provider: AIProvider, duration_seconds: int = 300):
    """
    ç†”æ–­æŒ‡å®šæä¾›å•†ï¼ˆä¸´æ—¶å±è”½ï¼‰
    
    Args:
        provider: AI æä¾›å•†
        duration_seconds: ç†”æ–­æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 5 åˆ†é’Ÿ
    """
    recovery_time = datetime.now().timestamp() + duration_seconds
    _provider_circuit_breaker[provider] = recovery_time
    logger.warning(f"ğŸ”´ Circuit breaking {provider.value} for {duration_seconds}s")


def get_model_for_provider(provider: AIProvider) -> str:
    """
    è·å–æŒ‡å®šæä¾›å•†çš„é»˜è®¤æ¨¡å‹å
    
    Args:
        provider: AI æä¾›å•†
    
    Returns:
        æ¨¡å‹åç§°
    """
    if provider == AIProvider.OPENAI:
        return settings.OPENAI_MODEL
    elif provider == AIProvider.DEEPSEEK:
        return settings.DEEPSEEK_MODEL
    else:
        return "gpt-4"


async def call_ai_with_fallback(
    messages: List[Dict[str, str]],
    temperature: float = 0.7,
    max_tokens: Optional[int] = None,
    response_format: Optional[Dict[str, Any]] = None,
) -> Tuple[Optional[str], Optional[AIProvider]]:
    """
    è°ƒç”¨ AI ç”Ÿæˆå›å¤ï¼ˆå¸¦è‡ªåŠ¨é™çº§ï¼‰

    é™çº§é¡ºåºï¼šåŸºäº settings.AI_PROVIDERS å’Œ settings.AI_PREFERRED_PROVIDER é…ç½®

    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user", "content": "..."}]
        temperature: æ¸©åº¦å‚æ•°
        max_tokens: æœ€å¤§ token æ•°
        response_format: å“åº”æ ¼å¼ï¼ˆä¾‹å¦‚ {"type": "json_object"}ï¼‰

    Returns:
        (ç”Ÿæˆçš„æ–‡æœ¬, ä½¿ç”¨çš„æä¾›å•†) æˆ– (None, None)
    """
    max_tokens = max_tokens or settings.OPENAI_MAX_TOKENS

    # 1. è·å–é…ç½®çš„æä¾›å•†åˆ—è¡¨
    configured_providers = settings.AI_PROVIDERS
    preferred_provider = settings.AI_PREFERRED_PROVIDER

    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼ˆç”±äºç¯å¢ƒå˜é‡è¯»å–å¯èƒ½æœªè¢« Pydantic è‡ªåŠ¨è§£æä¸º listï¼‰
    if isinstance(configured_providers, str):
        configured_providers = [p.strip() for p in configured_providers.split(",")]

    # 2. è½¬æ¢ä¸ºæšä¸¾å¹¶æ ¹æ®é¦–é€‰æ€§æ’åº
    providers = []
    for p_name in configured_providers:
        try:
            providers.append(AIProvider(p_name.lower().strip()))
        except ValueError:
            logger.warning(f"Unknown AI provider in settings: {p_name}")

    if preferred_provider:
        try:
            pref_enum = AIProvider(preferred_provider.lower().strip())
            if pref_enum in providers:
                providers.remove(pref_enum)
                providers.insert(0, pref_enum)
        except ValueError:
            pass

    # 3. å¦‚æœåˆ—è¡¨ä¸ºç©ºï¼Œæä¾›é»˜è®¤å›é€€
    if not providers:
        providers = [AIProvider.OPENAI, AIProvider.DEEPSEEK]
    
    # è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºæœ€ç»ˆå°è¯•çš„æä¾›å•†é¡ºåºï¼ˆä½¿ç”¨ warning çº§åˆ«ç¡®ä¿å¯è§ï¼‰
    logger.warning(f"ğŸ” AI Providers sequence: {[p.value for p in providers]}")

    last_error = None

    for provider in providers:
        # ç‰¹å¤–æ£€æŸ¥ DeepSeek æ˜¯å¦åœ¨é…ç½®ä¸­è¢«ç¦ç”¨
        if provider == AIProvider.DEEPSEEK and not settings.DEEPSEEK_ENABLED:
            logger.warning("â© DeepSeek is disabled, skipping")
            continue

        client = get_ai_client(provider)
        if not client:
            logger.warning(f"âš ï¸ {provider.value} client is None, skipping")
            continue

        model = get_model_for_provider(provider)
        logger.warning(f"ğŸ¤– Calling {provider.value} (model: {model})")

        try:
            kwargs = {
                "model": model,
                "messages": messages,
                "max_tokens": max_tokens,
            }

            # deepseek-reasoner: temperature/top_p ç­‰å‚æ•°æ— æ•ˆä½†ä¸ä¼šæŠ¥é”™ï¼Œä¿ç•™å…¼å®¹æ€§
            # ä½† response_format (JSON Output) æ˜¯è¢«å®˜æ–¹æ”¯æŒçš„ï¼Œä¸è¦å‰¥ç¦»
            if provider == AIProvider.DEEPSEEK and "reasoner" in model.lower():
                # reasoner æ¨¡å¼ï¼štemperature æ— æ•ˆï¼Œä¸ä¼ ä»¥ä¿æŒç®€æ´
                logger.warning(f"â„¹ï¸ Using {model} (reasoner mode): temperature ignored per API docs")
            else:
                kwargs["temperature"] = temperature

            if response_format:
                kwargs["response_format"] = response_format

            response = await client.chat.completions.create(**kwargs)
            message = response.choices[0].message
            content = message.content
            
            # è®°å½• DeepSeek çš„æ¨ç†è¿‡ç¨‹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            reasoning = getattr(message, 'reasoning_content', None)
            if reasoning:
                logger.info(f"AI Provider ({provider.value}) reasoning extracted | length: {len(reasoning)}")
            
            # â˜… å…³é”®ä¿®å¤ï¼šDeepSeek R1 æœ‰æ—¶ content ä¸ºç©ºï¼Œä½† reasoning_content ä¸­åŒ…å«æœ‰æ•ˆå†…å®¹
            # å°è¯•ä» reasoning_content ä¸­æå– JSON æˆ–æœ‰ç”¨æ–‡æœ¬
            if (not content or not content.strip()) and reasoning:
                logger.warning(f"AI Provider ({provider.value}) empty content, recovering from reasoning...")
                import re
                # ä¼˜å…ˆå°è¯•ä» reasoning ä¸­æå– JSON
                json_match = re.search(r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})', reasoning, re.DOTALL)
                if json_match:
                    content = json_match.group(1).strip()
                    logger.info(f"AI Provider ({provider.value}) JSON recovered from reasoning | length: {len(content)}")
                else:
                    # é JSON åœºæ™¯ï¼šå– reasoning æœ€åä¸€æ®µä½œä¸ºç»“è®º
                    paragraphs = [p.strip() for p in reasoning.split('\n\n') if p.strip()]
                    if paragraphs:
                        content = paragraphs[-1]
                        logger.info(f"AI Provider ({provider.value}) text recovered from reasoning | length: {len(content)}")
            
            # å¼ºåŒ–å¤„ç†ï¼šDeepSeek å³ä½¿åœ¨é JSON æ¨¡å¼ä¸‹ä¹Ÿå¯èƒ½è¿”å› <think> å—ï¼Œåº”å§‹ç»ˆå°†å…¶å‰¥ç¦»
            if content and provider == AIProvider.DEEPSEEK:
                if "<think>" in content and "</think>" in content:
                    logger.debug(f"AI Provider ({provider.value}) stripping <think> block")
                    content = content.split("</think>")[-1].strip()

            # å¦‚æœè¯·æ±‚äº† JSON æ ¼å¼ï¼Œè¿›ä¸€æ­¥æ¸…ç†å†…å®¹ï¼ˆå¤„ç† Markdown ä»£ç å—ç­‰ï¼‰
            if content and response_format and response_format.get("type") == "json_object":
                # 1. ç§»é™¤ Markdown ä»£ç å—
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    # æœ‰æ—¶å€™ AI ä¸å†™ json æ ‡ç­¾ï¼Œåªå†™ ```
                    parts = content.split("```")
                    if len(parts) >= 3:
                        # å–ä¸­é—´çš„éƒ¨åˆ†
                        content = parts[1].strip()
                
                # 3. å…œåº•ï¼šå¦‚æœè¿˜æ˜¯ä¸åƒ JSONï¼Œå°è¯•æå–ç¬¬ä¸€ä¸ª { åˆ°æœ€åä¸€ä¸ª } ä¹‹é—´çš„å†…å®¹
                if content and not (content.startswith("{") and content.endswith("}")):
                    import re
                    match = re.search(r"(\{.*\})", content, re.DOTALL)
                    if match:
                        logger.debug(f"AI Provider ({provider.value}) JSON regex extraction used")
                        content = match.group(1).strip()

            # â˜… å¦‚æœæœ€ç»ˆ content ä»ä¸ºç©ºï¼Œè§†ä¸ºæœ¬æ¬¡è°ƒç”¨å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª provider
            if not content or not content.strip():
                logger.warning(f"AI Provider ({provider.value}) failed to yield valid content")
                last_error = Exception(f"{provider.value} returned empty content")
                continue

            logger.info(f"AI Provider ({provider.value}) success | model: {model} | length: {len(content)}")
            return content, provider

        except Exception as e:
            error_str = str(e)
            logger.error(f"AI Provider ({provider.value}) error | model: {model} | {error_str}")
            last_error = e

            # æ£€æŸ¥æ˜¯å¦ç”±äºè¶…æ—¶ï¼ˆæœ‰äº›è¶…æ—¶é”™è¯¯ä¸å¸¦ 429 ç­‰çŠ¶æ€ç ï¼‰
            is_timeout = "timeout" in error_str.lower() or "deadline" in error_str.lower()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç†”æ–­ï¼ˆ429 é…é¢ä¸è¶³ã€401 è®¤è¯å¤±è´¥ï¼‰
            if "429" in error_str or "insufficient_quota" in error_str:
                circuit_break_provider(provider, duration_seconds=600)  # ç†”æ–­ 10 åˆ†é’Ÿ
            elif "401" in error_str or "authentication" in error_str.lower():
                circuit_break_provider(provider, duration_seconds=1800)  # ç†”æ–­ 30 åˆ†é’Ÿ
            elif is_timeout and provider == AIProvider.OPENAI:
                # OpenAI è¶…æ—¶é€šå¸¸æ˜¯ç½‘ç»œæˆ–ä»£ç†é—®é¢˜ï¼Œç†”æ–­ä¸€ä¼šä»¥åˆ‡æ¢åˆ°å¤‡ç”¨
                circuit_break_provider(provider, duration_seconds=120)

            # ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæä¾›å•†
            continue

    # æ‰€æœ‰æä¾›å•†éƒ½å¤±è´¥
    if last_error:
        logger.error(f"All AI providers failed. Last error from {providers[-1].value if providers else 'unknown'}: {last_error}")
    return None, None


async def get_available_providers() -> List[AIProvider]:
    """
    è·å–å½“å‰å¯ç”¨çš„ AI æä¾›å•†åˆ—è¡¨

    Returns:
        å¯ç”¨æä¾›å•†åˆ—è¡¨
    """
    available = []

    # æ£€æŸ¥ OpenAI
    if get_ai_client(AIProvider.OPENAI):
        available.append(AIProvider.OPENAI)

    # æ£€æŸ¥ DeepSeek
    if settings.DEEPSEEK_ENABLED and get_ai_client(AIProvider.DEEPSEEK):
        available.append(AIProvider.DEEPSEEK)

    return available


def get_circuit_breaker_status() -> Dict[str, Any]:
    """
    è·å–ç†”æ–­å™¨çŠ¶æ€
    
    Returns:
        ç†”æ–­å™¨çŠ¶æ€å­—å…¸
    """
    now = datetime.now().timestamp()
    status = {}
    
    for provider, recovery_time in _provider_circuit_breaker.items():
        remaining = int(recovery_time - now)
        if remaining > 0:
            status[provider.value] = {
                "broken": True,
                "recovery_in_seconds": remaining,
            }
    
    return status
